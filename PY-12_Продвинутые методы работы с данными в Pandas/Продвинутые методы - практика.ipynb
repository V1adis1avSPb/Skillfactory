{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ЗАДАНИЕ 6.3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим, в ваше распоряжение предоставлена директория \"./Root/users/\". В данной директории содержатся csv-файлы, в каждом из которых хранится информация об идентификаторах пользователей (user_id) и ссылки на их фотографии (photo_url). Каждый файл из папки users имеет примерно следующую структуру:\n",
    "\n",
    "Img\n",
    "\n",
    "При проверке в директории может быть сколько угодно файлов (директория может изменяться в зависимости от устройства файловой системы).\n",
    "\n",
    "Вам необходимо написать функцию concat_user_files(path), параметром которой является path — путь до директории. Функция должна объединить информацию из предоставленных вам файлов в один DataFrame и вернуть его. \n",
    "\n",
    "Список названий всех файлов, находящихся в директории, вы можете получить с помощью функции os.listdir(path) из модуля os (модуль уже импортирован в файле main.py). Например, для директории \"./Root/users/\" результатом работы функции будет список:\n",
    "\n",
    "print(os.listdir('./Root/users/'))\n",
    "['users2.csv', 'users1.csv', 'users3.csv']\n",
    "Примечание. Модуль os позволяет работать с операционной системой компьютера прямо из кода. Подробнее о нем вы можете почитать здесь.\n",
    "\n",
    "Отсортируйте этот список, прежде чем производить объединение файлов.\n",
    "\n",
    "Когда вы получите отсортированный список, вам останется только прочитать все csv-файлы из списка в цикле и объединить прочитанные таблицы между собой.\n",
    "\n",
    "Однако обратите внимание, что метод os.listdir() возвращает только список имён файлов в указанной директории, а при чтении файла необходимо указывать полный путь до него. То есть путь для чтения будет таким:\n",
    "\n",
    "'./Root/users/{file_name}'\n",
    "Не забудьте обновить индексы результирующей таблицы после объединения.\n",
    "\n",
    "Учтите, что на тестовом наборе файлов в результате объединения могут возникнуть дубликаты, от которых необходимо будет избавиться.\n",
    "\n",
    "Например, для директории \"./Root/users/\" результирующая таблица должна иметь следующий вид:\n",
    "\n",
    "Img\n",
    "\n",
    "При работе с заданием в Codeboard не используйте кириллицу — писать решение надо полностью на английском языке, иначе написанный вами код не запустится!\n",
    "\n",
    "Начните работу традиционно с открытия файла main.py — там вы увидите условие задачи.\n",
    "Впишите требуемый код и нажмите RUN.\n",
    "Нажмите SUBMIT, чтобы отправить ваш ответ на проверку и получить баллы в случае верного решения.\n",
    "✏️Дисклеймер: Обратите внимание, что по причине более старой версии pandas (0.13.1) в Codeboard метод drop_duplicates() не имеет аргумента ignore_index (он появился в версии 1.0.0). Мы работаем над данной проблемой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './Root/users/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m     df_sum \u001b[39m=\u001b[39m df_sum\u001b[39m.\u001b[39mdrop_duplicates(ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     12\u001b[0m     \u001b[39mreturn\u001b[39;00m(df_sum)\n\u001b[0;32m---> 14\u001b[0m \u001b[39mprint\u001b[39m(concat_user_files(\u001b[39m'\u001b[39;49m\u001b[39m./Root/users\u001b[39;49m\u001b[39m'\u001b[39;49m))\n",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m, in \u001b[0;36mconcat_user_files\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconcat_user_files\u001b[39m(path):\n\u001b[1;32m      5\u001b[0m     path \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 6\u001b[0m     list_names \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(os\u001b[39m.\u001b[39;49mlistdir(path))\n\u001b[1;32m      7\u001b[0m     df_sum \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39muser_id\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mimage_url\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      8\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(list_names)):\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './Root/users/'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def concat_user_files(path):\n",
    "    path += '/'\n",
    "    list_names = sorted(os.listdir(path))\n",
    "    df_sum = pd.DataFrame(columns=['user_id','image_url'])\n",
    "    for i in range(len(list_names)):\n",
    "        list_names[i]= path + list_names[i]\n",
    "        df_sum = pd.concat([df_sum, pd.read_csv(list_names[i])], ignore_index=True)\n",
    "    df_sum = df_sum.drop_duplicates(ignore_index=True)\n",
    "    return(df_sum)\n",
    "    \n",
    "print(concat_user_files('./Root/users'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ЗАДАНИЕ 7.5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Даны две таблицы: items_df, в которой содержится информация о наличии товаров на складе, и purchase_df — с данными о покупках товаров.\n",
    "\n",
    "items_df = pd.DataFrame({\n",
    "    'item_id': [417283, 849734, 132223, 573943, 19475, 3294095, 382043, 302948, 100132, 312394], \n",
    "    'vendor': ['Samsung', 'LG', 'Apple', 'Apple', 'LG', 'Apple', 'Samsung', 'Samsung', 'LG', 'ZTE'],\n",
    "    'stock_count': [54, 33, 122, 18, 102, 43, 77, 143, 60, 19]\n",
    "})\n",
    "purchase_df = pd.DataFrame({\n",
    "    'purchase_id': [101, 101, 101, 112, 121, 145, 145, 145, 145, 221],\n",
    "    'item_id': [417283, 849734, 132223, 573943, 19475, 3294095, 382043, 302948, 103845, 100132], \n",
    "    'price': [13900, 5330, 38200, 49990, 9890, 33000, 67500, 34500, 89900, 11400]\n",
    "})\n",
    "Информация в таблицах представлена в виде следующих столбцов:\n",
    "\n",
    "item_id — идентификатор модели;\n",
    "vendor — производитель модели;\n",
    "stock_count — имеющееся на складе количество данных моделей (в штуках);\n",
    "purchase_id — идентификатор покупки;\n",
    "price — стоимость модели в покупке.\n",
    "Сформируйте DataFrame merged, в котором в результате объединения purchase_df и items_df останутся модели, которые учтены на складе и имели продажи.\n",
    "Из таблицы merged найдите суммарную выручку, которую можно было бы получить от продажи всех товаров, которые учтены на складе и имели продажи. Результат занесите в переменную income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19729490"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "items_df = pd.DataFrame({\n",
    "    'item_id': [417283, 849734, 132223, 573943, 19475, 3294095, 382043, 302948, 100132, 312394],\n",
    "    'vendor': ['Samsung', 'LG', 'Apple', 'Apple', 'LG', 'Apple', 'Samsung', 'Samsung', 'LG', 'ZTE'],\n",
    "    'stock_count': [54, 33, 122, 18, 102, 43, 77, 143, 60, 19]\n",
    "})\n",
    "\n",
    "purchase_df = pd.DataFrame({\n",
    "    'purchase_id': [101, 101, 101, 112, 121, 145, 145, 145, 145, 221],\n",
    "    'item_id': [417283, 849734, 132223, 573943, 19475, 3294095, 382043, 302948, 103845, 100132],\n",
    "    'price': [13900, 5330, 38200, 49990, 9890, 33000, 67500, 34500, 89900, 11400]\n",
    "})\n",
    "\n",
    "merged = items_df.merge(purchase_df, how='inner')\n",
    "income = (merged['price']*merged['stock_count']).sum()\n",
    "# display(income)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
